# -*- coding: utf-8 -*-
"""TE_Mini-Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1emgR2uBv4WtP4GouV5B9DpnKpUCdrHx-

ðŸ‘‡ code for linking to drive for DATA
"""

# from google.colab import drive
# drive.mount('/content/drive')

"""### **Necessary Imports**"""

import random
import numpy as np
import matplotlib.pyplot as plt
import cv2
import os
from tqdm import tqdm
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, AveragePooling2D

"""### **Importing DataSet**"""

IMG_SIZE = 375
# Provide the path to the folder ðŸ‘‡ 
DATADIR = "/content/drive/MyDrive/DataSample"
CATEGORIES = ["non_blur", "blur"]
training_data = []

def create_training_data():
  """ This function creates a array of images & labels. Here the images are converted, resized and then stored"""
  for category in CATEGORIES:  # do non_blur and blur

        path = os.path.join(DATADIR,category)  # create path to non_blur and blur
        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=non_blur 1=blur

        for img in tqdm(os.listdir(path)):  # iterate over each image per non_blur and blur
            try:
                img_array = cv2.imread(os.path.join(path,img))  # convert to array
                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size
                training_data.append([new_array, class_num])  # add this to our training_data
            except Exception as e:  # in the interest in keeping the output clean...
                pass

create_training_data()
random.shuffle(training_data)

# it splits the traning_data array into images n labels in seperate list, using them we further divide them in test and train data

X = []
y = []

for features,label in training_data:
    X.append(features)
    y.append(label)


X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)
y = np.array(y).reshape(-1, 1)

X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.20, random_state=114)

"""ðŸ‘‡shows random image"""

idx = random.randint(0, len(X))
print(idx)
plt.figure(figsize=(7,9))
plt.imshow(X[idx, :])
plt.show()

"""## **Model**"""

model = Sequential([
    Conv2D(64, (3,3), activation = 'relu', input_shape = (375, 375, 3)),
    MaxPooling2D((2,2)),
    Conv2D(64, (3,3), activation = 'relu'),
    MaxPooling2D((2,2)),
    Flatten(),
    Dense(64, activation = 'relu'),
    Dense(2, activation = 'softmax')
])

model.compile(optimizer='adam',loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])

model.fit(X_train, y_train, epochs = 25, batch_size = 16)

model.evaluate(X_test, y_test)

"""### **Prediction**"""

idx2 = random.randint(0, len(y_test))
plt.figure(figsize=(7,9))
plt.imshow(X_test[idx2, :])
plt.show()

y_pred = model.predict(X_test[idx2, :].reshape(1, 375, 375, 3))
y_pred = y_pred > 0.5
print(y_pred)
if(y_pred[0][0]):
    pred = 'non_blur'
elif(not y_pred[0][0]):
    pred = 'blur'
    
print("Our model says the image is :", pred)
